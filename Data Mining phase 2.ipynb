{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125c88bc",
   "metadata": {},
   "source": [
    "# Data Mining Project Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55536bcb",
   "metadata": {},
   "source": [
    "Faridreza Momtaz Zandi 9812762601\n",
    "Alireza Noorbakhsh 9812762496"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653075db",
   "metadata": {},
   "source": [
    "In this phase, our main goal is to work on our data and have a clear mindset of how is our dataset's quality. We'll achieve this goal by evaluating five inherent quality attributes: Accuracy, Completeness, Consistency, Credibility, and Currentness. Only after using all these models, we can have a full understanding on how's the quality of our data but we'll see later on that most of our data isn't suitable for our data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a5088",
   "metadata": {},
   "source": [
    "Before we start on our datasets let's see what are these five quality model attributes.\n",
    "Accuracy: The degree to which data has attributes that correctly represent the true value of the intended attribute of a concept or event in a specific context of use.\n",
    "Completeness: The degree to which subject data associated with an entity has values for all expected attributes and related entity instances in a specific context of use.\n",
    "Consistency: The degree to which data has attributes that are free from contradiction and are coherent with other data in a specific context of use. It can be either or both among data regarding one entity and across similar data for comparable entities.\n",
    "Credibility: The degree to which data has attributes that are regarded as true and believable by users in a specific context of use. Credibility includes the concept of authenticity (the truthfulness of origins, attributions, and commitments).\n",
    "Currentness: The degree to which data has attributes that are of the right age in a specific context of use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1886594",
   "metadata": {},
   "source": [
    "#  INOUT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13969fd6",
   "metadata": {},
   "source": [
    "As we said before in phase one there are no specific and clear attributes to find the quality of it and even if we find the null count or other quality model attributes we won't be able to use this data in any useful way. So it's better to skip this dataset and get to one with more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7175208c",
   "metadata": {},
   "source": [
    "# INOUTLINE Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c7ceec",
   "metadata": {},
   "source": [
    "Again like in the last Phase, now in this dataset, we can work on some attributes which we have found before. these attributes are ACCUMULATEDEPRECIATION, BOOKVALUE, PRIMALVALUE and DEPRECATION_PERIOD. first, we'll find the total count of their record and null counts and then we'll talk about our quality model attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4204995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec1ec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m Lets see these columns info first, this gives us total record and non-null count:\n",
      "\u001b[90m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103410 entries, 0 to 103409\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   ACCUMULATEDEPRECIATION  7680 non-null    float64\n",
      " 1   BOOKVALUE               66503 non-null   float64\n",
      " 2   PRIMALVALUE             103342 non-null  float64\n",
      " 3   DEPRECATION_PERIOD      4 non-null       float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.2 MB\n",
      "None\n",
      "\u001b[95m So our null count is:\n",
      "\u001b[90m\n",
      "ACCUMULATEDEPRECIATION     95730\n",
      "BOOKVALUE                  36907\n",
      "PRIMALVALUE                   68\n",
      "DEPRECATION_PERIOD        103406\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\ce\\data mining\\DataSets\\INOUTLINE.csv' , low_memory = False)\n",
    "df = df[['ACCUMULATEDEPRECIATION' , 'BOOKVALUE' , 'PRIMALVALUE' ,'DEPRECATION_PERIOD']]\n",
    "print('\\033[94m Lets see these columns info first, this gives us total record and non-null count:')\n",
    "print('\\033[90m')\n",
    "print(df.info())\n",
    "print('\\033[95m So our null count is:')\n",
    "print('\\033[90m')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ddf053",
   "metadata": {},
   "source": [
    "Accuracy: for example when we look at ACCUMULATEDEPRECIATION attributes there is no data out of acceptable range so we can imagine accuracy is considered and there is no other way to make sure cause we do not know the exact or wished range!\n",
    "this is also true for other chosen attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ac61b",
   "metadata": {},
   "source": [
    "Completeness: for each attribute, we just need to find the non-null to all ratio so we have: ACCUMULATEDEPRECIATION: 7.42%, BOOKVALUE: 64.31%, PRIMALVALUE: 99.94% and DEPRECATION_PERIOD: 0.004%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38872c6f",
   "metadata": {},
   "source": [
    "Consistency: after taking a look at our attributes we see DEPRECATION_PERIOD, BOOKVALUE and PRIMALVALUE are value types, and there is no specific rule that we can have for them but on the other hand DEPRECATION_PERIOD which is Depreciation period might be in contact with other attributes such as ENDOFUSEFULLIFE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1444028",
   "metadata": {},
   "source": [
    "Credibility: for this quality model attribute we take the same approach we did with accuracy and while having not enough knowledge about our dataset there is no way to have a valid evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217430d",
   "metadata": {},
   "source": [
    "Currentness: We can only accept what our data provider promised and there isn't any other way to check if our data is up to date or even updated enough to not put us in any trouble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f611d",
   "metadata": {},
   "source": [
    "# PRODUCTINSTANCE Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33642b6",
   "metadata": {},
   "source": [
    "We proceed like the previous dataset and first take a look at our chosen attributes from the last phase which are: PRICE9, SALVAGEVALUE, PI_VALUEAFTERCOEFFICIENTINC, COEFFICIENTVALUE, ANTIQUITYCOEFFICIENT, PRESENTVALUE, BOOKVALUE and AREA_TOTAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5919aec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m Lets see these columns info first, this gives us total record and non-null count:\n",
      "\u001b[90m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 706204 entries, 0 to 706203\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   PRICE9                       660 non-null     float64\n",
      " 1   SALVAGEVALUE                 6795 non-null    float64\n",
      " 2   PI_VALUEAFTERCOEFFICIENTINC  3332 non-null    float64\n",
      " 3   COEFFICIENTVALUE             3105 non-null    float64\n",
      " 4   ANTIQUITYCOEFFICIENT         3105 non-null    float64\n",
      " 5   PRESENTVALUE                 834 non-null     float64\n",
      " 6   BOOKVALUE                    130898 non-null  float64\n",
      " 7   AREA_TOTAL                   388455 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 43.1 MB\n",
      "None\n",
      "\u001b[95m So our null count is:\n",
      "\u001b[90m\n",
      "PRICE9                         705544\n",
      "SALVAGEVALUE                   699409\n",
      "PI_VALUEAFTERCOEFFICIENTINC    702872\n",
      "COEFFICIENTVALUE               703099\n",
      "ANTIQUITYCOEFFICIENT           703099\n",
      "PRESENTVALUE                   705370\n",
      "BOOKVALUE                      575306\n",
      "AREA_TOTAL                     317749\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\ce\\data mining\\DataSets\\PRODUCTINSTANCE.csv' , encoding='cp1252' , low_memory=False)\n",
    "df = df[['PRICE9' , 'SALVAGEVALUE' , 'PI_VALUEAFTERCOEFFICIENTINC' , 'COEFFICIENTVALUE' , 'ANTIQUITYCOEFFICIENT'\n",
    "       , 'PRESENTVALUE' , 'BOOKVALUE' , 'AREA_TOTAL']]\n",
    "print('\\033[94m Lets see these columns info first, this gives us total record and non-null count:')\n",
    "print('\\033[90m')\n",
    "print(df.info())\n",
    "print('\\033[95m So our null count is:')\n",
    "print('\\033[90m')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986bcd2",
   "metadata": {},
   "source": [
    "This time we're checking eight attributes but almost all quality model attributes work the same as our last dataset for example there isn't any specific data about some attributes such as PRICE9, SALVAGEVALUE, and PI_VALUEAFTERCOEFFICIENTINC and with limited knowledge like this, there is no way to have a Safe choice for accuracy and credibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e4043",
   "metadata": {},
   "source": [
    "Completeness: unlike accuracy and credibility we can have an almost accurate rate for completeness which is: PRICE9: 0.01%, SALVAGEVALUE: 0.96%, PI_VALUEAFTERCOEFFICIENTINC: 0.47%, COEFFICIENTVALUE: 0.43%, ANTIQUITYCOEFFICIENT: 0.43%, PRESENTVALUE: 0.12%, BOOKVALUE: 18.54% and AREA_TOTAL : 55.01%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03847016",
   "metadata": {},
   "source": [
    "Again there isn't enough description in our dictionary about these attributes so we can't make sure our data is consistent. And once again we need to believe our data provider whatever he says about the currentness of our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5240e",
   "metadata": {},
   "source": [
    "# TRANSFER_ITEM and TRANSFER_ITEM_D Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45ad48",
   "metadata": {},
   "source": [
    "As we talked about before there isn't any useful insight we can from these datasets even if we check it's record count or the null count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee6348",
   "metadata": {},
   "source": [
    "For the next part of this phase, we wish to find some examples of Data Quality Problems which we categorize into two main groups: Single-Source Problems(schema/instant) and Multi-Source Problems(Shema/instant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566957ab",
   "metadata": {},
   "source": [
    "# Single-Source Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65161866",
   "metadata": {},
   "source": [
    "The data quality of a source largely depends on the degree to which it is governed by schema and integrity constraints controlling permissible data values. Schema-related data quality problems thus occur because of the lack of appropriate model-specific or application-specific integrity constraints, e.g., due to data model limitations or poor schema design, or because only a few integrity constraints were defined to limit the overhead for integrity control. Instance-specific problems relate to errors and inconsistencies that cannot be prevented at the schema level (e.g., misspellings). Now let's try to find some single-source problems in our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ecd72",
   "metadata": {},
   "source": [
    "One of the most obvious single source problems are missing values in attribute scope and is an instance level problem which we saw in the last part how much of an attribute is null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e82d7",
   "metadata": {},
   "source": [
    "If we look closely at INOUT dataset and especially at the DESCRIPTION attribute we see some records are integer but are shown in a way that can't be accessed and somehow has some question marks before and after the number we need! this is also an instance level problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885818b7",
   "metadata": {},
   "source": [
    "We can find an embedded value problem in the PRODUCTINSTANCE dataset and PARENT_ID attribute which we have both string and integer attributes and this is a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefd238",
   "metadata": {},
   "source": [
    "# Multi-Source problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406e94e",
   "metadata": {},
   "source": [
    "The problems present in single sources are aggravated when multiple sources need to be integrated. Each source may contain dirty data and the data in the sources may be represented differently, overlap, or contradict. This is because the sources are typically developed, deployed, and maintained independently to serve specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55f600",
   "metadata": {},
   "source": [
    "One of the things we need to check for multi-source problems is the probability of causing a problem in case of merging datasets or extracting a single product data from different datasets, for example, if we merge INOUTLINE dataset with TRANSFER_ITEM, both have C_YEAR_ID attribute which is Fiscal year and we may get the same record but with a different value for C_YEAR_ID. We can use this situation to show one more probable multi-source problem which is showing the date in different ways such as using the year in a full format like 2022 or only the second two digits like 22."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ff247",
   "metadata": {},
   "source": [
    "If we look closely at INOUTLINE data set and DISCRIPTIONKALA attribute we can guess having two languages for records might have happened because of a multi-source problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba385a",
   "metadata": {},
   "source": [
    "When we examine the product dataset we'll find it very messy and it can be an example of multi-source problems. Almost any problem at any level can be found! other than lots of null records and missing data it suffers from being inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a61502",
   "metadata": {},
   "source": [
    "# suggestions for data quality improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804c943",
   "metadata": {},
   "source": [
    "In my opinion, the biggest flaw of our datasets is the missing values, as we saw in this phase we're suffering from a huge rate of missing data even in our critical records, so my first suggestion is to handle these missing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a98e64d",
   "metadata": {},
   "source": [
    "The second problem with these datasets is how much messy it is! especially with datasets like PRODUCTS. If data is too dirty we can't have a clear solution to how to use this data so we have to clean it. This cleaning can be filling out null records or removing noises and even Correcting inconsistent data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280f88f",
   "metadata": {},
   "source": [
    "The last thing that comes to mind when working on our datasets is that it was really to our advantage if we had a better dictionary or at least more information about our attributes. It's frustrating figuring out a dataset with nest to minimum knowledge about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
