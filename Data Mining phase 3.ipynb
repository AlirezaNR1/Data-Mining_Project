{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c1a701",
   "metadata": {},
   "source": [
    "# Data Mining Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f00601",
   "metadata": {},
   "source": [
    "Faridreza Momtazzandi 9812762601 Alireza Nourbakhsh 9812762496"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fc7c8",
   "metadata": {},
   "source": [
    "After all the knowledge we got from our previous two phases now we have enough information to finally get some specific insight on how we can use our analysis result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc385431",
   "metadata": {},
   "source": [
    "In this phase we're asked to find out about three different objectives in our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3de561",
   "metadata": {},
   "source": [
    "# 1. Incoming rate of assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349ab37",
   "metadata": {},
   "source": [
    "Our first task is to Find the ratio of incoming assets based on year which can be Fiscal year or normal year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28e3fe",
   "metadata": {},
   "source": [
    "As we said before we'll be focusing on INOUT and INOUTLINE datasets which mostly has the information on ingoing and outgoing assetss. So let's figure out which year we want to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe129d8",
   "metadata": {},
   "source": [
    "If we want to use a fiscal year, unfortunately, most of our records don't have value and are null so another way we can deal with year is to use CREATED feature which we have in both INOUT and INOUTLINE so let's get to coding for a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b602e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41265ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inout_df = pd.read_csv('E:\\ce\\data mining\\DataSets\\INOUT.csv' , low_memory = False)\n",
    "inoutline_df = pd.read_csv('E:\\ce\\data mining\\DataSets\\INOUTLINE.csv' , low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8877a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m Lets see how much asset came in on each year and how we documented it in INOUT dataset:\n",
      "\u001b[90m\n",
      "in 2015: 1071\n",
      "in 2016: 947\n",
      "in 2017: 1291\n",
      "in 2018: 1208\n",
      "in 2019: 851\n",
      "in 2020: 992\n",
      "in 2021: 727\n",
      "in 2022: 512\n"
     ]
    }
   ],
   "source": [
    "year_2015 = 0 \n",
    "year_2016 = 0 \n",
    "year_2017 = 0 \n",
    "year_2018 = 0 \n",
    "year_2019 = 0 \n",
    "year_2020 = 0 \n",
    "year_2021 = 0 \n",
    "year_2022 = 0 \n",
    "\n",
    "for ind in inout_df.index:\n",
    "    if '2015' in inout_df['CREATED'][ind]:\n",
    "        year_2015 += 1\n",
    "    elif '2016' in inout_df['CREATED'][ind]:\n",
    "        year_2016 += 1\n",
    "    elif '2017' in inout_df['CREATED'][ind]:\n",
    "        year_2017 += 1\n",
    "    elif '2018' in inout_df['CREATED'][ind]:\n",
    "        year_2018 += 1\n",
    "    elif '2019' in inout_df['CREATED'][ind]:\n",
    "        year_2019 += 1\n",
    "    elif '2020' in inout_df['CREATED'][ind]:\n",
    "        year_2020 += 1\n",
    "    elif '2021' in inout_df['CREATED'][ind]:\n",
    "        year_2021 += 1\n",
    "    elif '2022' in inout_df['CREATED'][ind]:\n",
    "        year_2022 += 1\n",
    "print('\\033[94m Lets see how much asset came in on each year and how we documented it in INOUT dataset:')\n",
    "print('\\033[90m')\n",
    "print('in 2015:' , year_2015)\n",
    "print('in 2016:' , year_2016)\n",
    "print('in 2017:' , year_2017)\n",
    "print('in 2018:' , year_2018)\n",
    "print('in 2019:' , year_2019)\n",
    "print('in 2020:' , year_2020)\n",
    "print('in 2021:' , year_2021)\n",
    "print('in 2022:' , year_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f136f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m Now we can do the same thing for our INOUTLINE dataset:\n",
      "\u001b[90m\n",
      "in 2013: 1\n",
      "in 2014: 0\n",
      "in 2015: 3326\n",
      "in 2016: 4448\n",
      "in 2017: 8245\n",
      "in 2018: 6228\n",
      "in 2019: 5374\n",
      "in 2020: 9191\n",
      "in 2021: 5227\n",
      "in 2022: 61370\n"
     ]
    }
   ],
   "source": [
    "print('\\033[94m Now we can do the same thing for our INOUTLINE dataset:')\n",
    "print('\\033[90m')\n",
    "year_2013 = 0 \n",
    "year_2014 = 0 \n",
    "year_2015 = 0 \n",
    "year_2016 = 0 \n",
    "year_2017 = 0 \n",
    "year_2018 = 0 \n",
    "year_2019 = 0 \n",
    "year_2020 = 0 \n",
    "year_2021 = 0 \n",
    "year_2022 = 0 \n",
    "\n",
    "for ind in inoutline_df.index:\n",
    "    if '2013' in inoutline_df['CREATED'][ind]:\n",
    "        year_2013 += 1\n",
    "    elif '2014' in inoutline_df['CREATED'][ind]:\n",
    "        year_2014 += 1\n",
    "    elif '2015' in inoutline_df['CREATED'][ind]:\n",
    "        year_2015 += 1\n",
    "    elif '2016' in inoutline_df['CREATED'][ind]:\n",
    "        year_2016 += 1\n",
    "    elif '2017' in inoutline_df['CREATED'][ind]:\n",
    "        year_2017 += 1\n",
    "    elif '2018' in inoutline_df['CREATED'][ind]:\n",
    "        year_2018 += 1\n",
    "    elif '2019' in inoutline_df['CREATED'][ind]:\n",
    "        year_2019 += 1\n",
    "    elif '2020' in inoutline_df['CREATED'][ind]:\n",
    "        year_2020 += 1\n",
    "    elif '2021' in inoutline_df['CREATED'][ind]:\n",
    "        year_2021 += 1\n",
    "    elif '2022' in inoutline_df['CREATED'][ind]:\n",
    "        year_2022 += 1\n",
    "print('in 2013:' , year_2013)\n",
    "print('in 2014:' , year_2014)\n",
    "print('in 2015:' , year_2015)\n",
    "print('in 2016:' , year_2016)\n",
    "print('in 2017:' , year_2017)\n",
    "print('in 2018:' , year_2018)\n",
    "print('in 2019:' , year_2019)\n",
    "print('in 2020:' , year_2020)\n",
    "print('in 2021:' , year_2021)\n",
    "print('in 2022:' , year_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954095bf",
   "metadata": {},
   "source": [
    "After getting all the incoming assets based on year we can analyze the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9466c86f",
   "metadata": {},
   "source": [
    "First, after a quick look at the result, we see almost all the assets in both datasets had been registered after 2015 and only one asset was registered before that so we can guess it's a noise and a mistake and probably best to just ignore it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c432b",
   "metadata": {},
   "source": [
    "Also, we can get some useful information about our datasets such as the years which had the most incoming assets which are 2017 and 2018 in the INOUT data set and by a long difference 2022 in the INOUTLINE dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c5734",
   "metadata": {},
   "source": [
    "# 2. Count and Value of assets based on Holding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b12993",
   "metadata": {},
   "source": [
    "Now in the second part of this phase, we need to get statistical knowledge on how each of our holdings is doing so we're trying to examine both INOUT and INOUTLINE databases on the value and count of registered data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4f447",
   "metadata": {},
   "source": [
    "For this part, we're trying to look for the ACCT_AC_HOLDING_ID feature which is the id number of the holding responsible for some assets and we examine it to see how each record of this feature represents a holding. We can also use the VAHED_MALI feature to check what accounting unit did the accounting for these assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0ba75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m All the holdings in INOUT dataset asset counts are:\n",
      "\u001b[90m\n",
      "1.0     7180\n",
      "3.0      289\n",
      "4.0       86\n",
      "5.0       24\n",
      "21.0      19\n",
      "Name: ACCT_AC_HOLDING_ID, dtype: int64\n",
      "\u001b[94m All the accounting units in INOUT dataset asset counts are:\n",
      "\u001b[90m\n",
      "200000138.0    6472\n",
      "469638358.0     154\n",
      "200000141.0      59\n",
      "200000130.0      46\n",
      "469638568.0      43\n",
      "200000192.0      41\n",
      "469638115.0      36\n",
      "200000114.0      24\n",
      "469678455.0      18\n",
      "210000001.0      15\n",
      "200000142.0      15\n",
      "200000679.0       8\n",
      "200000491.0       7\n",
      "200000696.0       5\n",
      "469718709.0       5\n",
      "200000538.0       4\n",
      "200000529.0       3\n",
      "1.0               1\n",
      "200000599.0       1\n",
      "200000523.0       1\n",
      "200000143.0       1\n",
      "469638210.0       1\n",
      "200000531.0       1\n",
      "469638544.0       1\n",
      "200000471.0       1\n",
      "Name: VAHED_MALI, dtype: int64\n",
      "\u001b[94m All the accounting units in INOUTLINE dataset asset counts are:\n",
      "\u001b[90m\n",
      "200000138.0    77242\n",
      "200000141.0     7226\n",
      "469678455.0     3421\n",
      "210000001.0     2104\n",
      "469638358.0      671\n",
      "469638568.0      221\n",
      "200000143.0      189\n",
      "200000679.0      158\n",
      "200000192.0      151\n",
      "469638115.0       76\n",
      "200000130.0       70\n",
      "210000112.0       63\n",
      "200000114.0       58\n",
      "200000529.0       40\n",
      "200000142.0       34\n",
      "200000538.0       25\n",
      "200000491.0       20\n",
      "469637613.0       16\n",
      "200000546.0       11\n",
      "200000696.0       10\n",
      "200000135.0        9\n",
      "200000548.0        9\n",
      "469638544.0        6\n",
      "200000523.0        5\n",
      "200000542.0        5\n",
      "200000531.0        5\n",
      "469718709.0        5\n",
      "200000471.0        5\n",
      "200000550.0        3\n",
      "200000484.0        3\n",
      "200000525.0        1\n",
      "200000599.0        1\n",
      "469638210.0        1\n",
      "Name: VAHED_MALI, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[94m All the holdings in INOUT dataset asset counts are:')\n",
    "print('\\033[90m')\n",
    "print(inout_df['ACCT_AC_HOLDING_ID'].value_counts())\n",
    "\n",
    "print('\\033[94m All the accounting units in INOUT dataset asset counts are:')\n",
    "print('\\033[90m')\n",
    "print(inout_df['VAHED_MALI'].value_counts())\n",
    "\n",
    "print('\\033[94m All the accounting units in INOUTLINE dataset asset counts are:')\n",
    "print('\\033[90m')\n",
    "print(inoutline_df['VAHED_MALI'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53945070",
   "metadata": {},
   "source": [
    "Let's calculate the values for each holding in INOUT dataset and 5 most accounting units in both datasets, but unfortunately, there is no book value in INOUT dataset so we have to move on to INOUTLINE dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280f54c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m With the code down below we try to calculate the sum of book values base on accounting units\n",
      "But unfortunatly as we try to get book values we see most of them are NaN or null\n",
      "so there is no usefull data to get from them we print accounting_unit_469638568 book values to show this\n",
      "\u001b[90m\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "accounting_unit_200000138 = 0\n",
    "accounting_unit_469638358 = 0\n",
    "accounting_unit_200000141 = 0\n",
    "accounting_unit_200000130 = 0\n",
    "accounting_unit_469638568 = 0\n",
    "\n",
    "print('\\033[94m With the code down below we try to calculate the sum of book values base on accounting units')\n",
    "print('But unfortunatly as we try to get book values we see most of them are NaN or null')\n",
    "print('so there is no usefull data to get from them we print accounting_unit_469638568 book values to show this')\n",
    "\n",
    "print('\\033[90m')\n",
    "\n",
    "for ind in inoutline_df.index:\n",
    "    if (inoutline_df['VAHED_MALI'][ind] == 200000138):\n",
    "        accounting_unit_200000138 = accounting_unit_200000138 + inoutline_df['BOOKVALUE'][ind]        \n",
    "    elif inoutline_df['VAHED_MALI'][ind] == 469638358:\n",
    "        accounting_unit_469638358 = accounting_unit_469638358 + inoutline_df['BOOKVALUE'][ind]\n",
    "    elif inoutline_df['VAHED_MALI'][ind] == 200000141:\n",
    "        accounting_unit_200000141 = accounting_unit_200000141 + inoutline_df['BOOKVALUE'][ind]\n",
    "    elif inoutline_df['VAHED_MALI'][ind] == 200000130:\n",
    "        accounting_unit_200000130 = accounting_unit_200000130 + inoutline_df['BOOKVALUE'][ind]\n",
    "    elif inoutline_df['VAHED_MALI'][ind] == 469638568:\n",
    "        accounting_unit_469638568 = accounting_unit_469638568 + inoutline_df['BOOKVALUE'][ind]\n",
    "        print(inoutline_df['BOOKVALUE'][ind])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87157316",
   "metadata": {},
   "source": [
    "# 3. Draft or finalized accounting document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98619bd",
   "metadata": {},
   "source": [
    "For this part, we need to check INOUT dataset and look for the C_DOCSTATUS_ID feature. This feature has three values: 3000025 for finalized, 3000006 for drafted, and 3000018 for waiting. We need to check each one of them to understand the state of each asset's accounting document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89192bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000025    7583\n",
      "3000006      14\n",
      "3000018       1\n",
      "6000035       1\n",
      "3309          1\n",
      "Name: C_DOCSTATUS_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(inout_df['C_DOCSTATUS_ID'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5533fc",
   "metadata": {},
   "source": [
    "As we saw in the result of the code above 7583 assets have been finalized and 14 assets are drafted and only 1 asset is in the waiting process, also 2 assets have the C_DOCSTATUS_ID value of 6000035 and 3309 which we don't know the meaning of so we can assume are mistaken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf4ce3",
   "metadata": {},
   "source": [
    "The only thing left in this phase is to get the list of these three states of accounting documents which we get in the below codes and after putting them into separated data frames we print the newly made data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87bb825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       INOUT_ID  AD_CLIENT_ID  AD_ORG_ID ISACTIVE          CREATED  CREATEDBY  \\\n",
      "0     469637755     104000002          0        Y   6/28/2015 7:50  210619032   \n",
      "1     469637756     104000002          0        Y   6/28/2015 7:50  210619032   \n",
      "2     469637757     104000002          0        Y   6/28/2015 7:50  210619032   \n",
      "3     469637758     104000002          0        Y   6/28/2015 7:50  210619032   \n",
      "4     469637759     104000002          0        Y   6/28/2015 7:50  210619032   \n",
      "...         ...           ...        ...      ...              ...        ...   \n",
      "7593  469647795     104000002          0        Y   9/8/2022 10:05  469637406   \n",
      "7594  469647814     104000002          0        Y   9/12/2022 9:16  469637406   \n",
      "7595  469647815     104000002          0        Y  9/12/2022 10:21  469637406   \n",
      "7597  469647817     104000002          0        Y  9/12/2022 11:22  469637406   \n",
      "7598  469647818     104000002          0        Y  9/12/2022 12:59  469637406   \n",
      "\n",
      "              UPDATED  UPDATEDBY  NAME DESCRIPTION  ... SUB_REF_ORG  STRING3  \\\n",
      "0     11/8/2017 11:15  210033614   NaN          69  ...         NaN      NaN   \n",
      "1      6/28/2015 7:50  210619032   NaN          73  ...         NaN      NaN   \n",
      "2      6/28/2015 7:50  210619032   NaN         206  ...         NaN      NaN   \n",
      "3      6/28/2015 7:50  210619032   NaN        9405  ...         NaN      NaN   \n",
      "4      6/28/2015 7:50  210619032   NaN         346  ...         NaN      NaN   \n",
      "...               ...        ...   ...         ...  ...         ...      ...   \n",
      "7593   9/8/2022 10:07  469637406   NaN         NaN  ...   265272107    24/15   \n",
      "7594   9/12/2022 9:17  469637406   NaN         NaN  ...   265272107    24/15   \n",
      "7595  9/12/2022 10:24  469637406   NaN         NaN  ...   265272107        1   \n",
      "7597  9/12/2022 11:33  469637406   NaN         NaN  ...   265272107    24/72   \n",
      "7598  9/12/2022 13:01  469637406   NaN         NaN  ...   265272107      NaN   \n",
      "\n",
      "      M_INOUT_AMVAL_ID DOCUMENTNO1 LOCATIONS_ID  ACCT_AC_HOLDING_ID  \\\n",
      "0                  NaN        69.0          NaN                 1.0   \n",
      "1                  NaN        73.0          NaN                 1.0   \n",
      "2                  NaN       206.0          NaN                 1.0   \n",
      "3                  NaN      9405.0          NaN                 1.0   \n",
      "4                  NaN       346.0          NaN                 1.0   \n",
      "...                ...         ...          ...                 ...   \n",
      "7593               NaN         NaN    1000050.0                 1.0   \n",
      "7594               NaN         NaN    1000050.0                 1.0   \n",
      "7595               NaN         NaN    1000050.0                 1.0   \n",
      "7597               NaN         NaN    1000196.0                 1.0   \n",
      "7598               NaN         NaN    1000050.0                 1.0   \n",
      "\n",
      "       VAHED_MALI  ACCT_AC_JOURNAL_ID  BASEINFO_RECORDID    C_YEAR_ID  \n",
      "0     200000138.0         470900574.0                NaN          NaN  \n",
      "1     200000138.0         470900574.0                NaN          NaN  \n",
      "2     200000138.0         470900574.0                NaN          NaN  \n",
      "3     200000138.0         470900574.0                NaN          NaN  \n",
      "4     200000138.0         470900574.0                NaN          NaN  \n",
      "...           ...                 ...                ...          ...  \n",
      "7593  200000138.0                 NaN        469638651.0  470737412.0  \n",
      "7594  200000138.0                 NaN        469638651.0  470737412.0  \n",
      "7595  200000138.0                 NaN        469638651.0  470737412.0  \n",
      "7597  469638568.0              2443.0        469638671.0  470737412.0  \n",
      "7598  200000138.0                 NaN        469638651.0  470737412.0  \n",
      "\n",
      "[7583 rows x 43 columns]\n",
      "       INOUT_ID  AD_CLIENT_ID  AD_ORG_ID ISACTIVE           CREATED  \\\n",
      "1466  469639217     104000002          0        Y   7/12/2016 15:09   \n",
      "2269  469640047     104000002          0        Y     3/7/2017 8:58   \n",
      "2270  469640048     104000002          0        Y     3/7/2017 9:01   \n",
      "2271  469640049     104000002          0        Y     3/7/2017 9:15   \n",
      "2990  469640796     104000002          0        Y   10/18/2017 8:19   \n",
      "3462  469641285     104000002          0        Y   2/25/2018 12:32   \n",
      "4361  469642220     104000002          0        Y    12/8/2018 8:17   \n",
      "5616  469643504     104000002          0        Y     6/8/2020 8:50   \n",
      "6663  469644634     104000002  104000002        Y    7/3/2021 14:01   \n",
      "6894  469645454     104000002  104000002        Y  11/27/2021 10:35   \n",
      "7522  469647353     104000002          0        Y     8/3/2022 8:34   \n",
      "7580  469647760     104000002          0        Y    9/4/2022 15:12   \n",
      "7596  469647837     104000002          0        Y   9/13/2022 10:18   \n",
      "7599  469647835     104000002          0        Y   9/13/2022 10:01   \n",
      "\n",
      "      CREATEDBY           UPDATED  UPDATEDBY  NAME  \\\n",
      "1466  210032662    9/3/2016 11:21  210032662   NaN   \n",
      "2269  210032662     3/7/2017 8:58  210032662   NaN   \n",
      "2270  210032662     3/7/2017 9:04  210032662   NaN   \n",
      "2271  210032662     3/7/2017 9:15  210032662   NaN   \n",
      "2990  210032662   10/18/2017 8:19  210032662   NaN   \n",
      "3462  210032662   2/25/2018 12:32  210032662   NaN   \n",
      "4361  210032662    12/8/2018 8:17  210032662   NaN   \n",
      "5616  469638254     6/8/2020 8:50  469638254   NaN   \n",
      "6663  469637406     8/7/2021 8:24  469637406   NaN   \n",
      "6894  469637406  11/27/2021 13:26  469637406   NaN   \n",
      "7522  210032977     8/3/2022 8:34  210032977   NaN   \n",
      "7580  210032977    9/4/2022 15:12  210032977   NaN   \n",
      "7596  210033167   9/13/2022 10:18  210033167   NaN   \n",
      "7599  210033167   9/13/2022 10:01  210033167   NaN   \n",
      "\n",
      "                                            DESCRIPTION  ... SUB_REF_ORG  \\\n",
      "1466  ???? ??????? ????? ?? ?????? ??????? ????? ???...  ...         NaN   \n",
      "2269                                                NaN  ...         NaN   \n",
      "2270                                                NaN  ...         NaN   \n",
      "2271                                                NaN  ...         NaN   \n",
      "2990                                                NaN  ...         NaN   \n",
      "3462                                                NaN  ...         NaN   \n",
      "4361                                                NaN  ...         NaN   \n",
      "5616                                                NaN  ...         NaN   \n",
      "6663                                                NaN  ...   265272107   \n",
      "6894                                                NaN  ...   265272107   \n",
      "7522                                                NaN  ...   265272107   \n",
      "7580                                                NaN  ...   265272107   \n",
      "7596                                                NaN  ...   265272107   \n",
      "7599                                                NaN  ...   265272107   \n",
      "\n",
      "      STRING3  M_INOUT_AMVAL_ID DOCUMENTNO1 LOCATIONS_ID  ACCT_AC_HOLDING_ID  \\\n",
      "1466      NaN               NaN         NaN          NaN                 1.0   \n",
      "2269      NaN               NaN         NaN          NaN                 1.0   \n",
      "2270      NaN               NaN         NaN          NaN                 1.0   \n",
      "2271      NaN               NaN         NaN          NaN                 1.0   \n",
      "2990      NaN               NaN         NaN          NaN                 1.0   \n",
      "3462      NaN               NaN         NaN          NaN                 1.0   \n",
      "4361      NaN               NaN         NaN          NaN                 1.0   \n",
      "5616      NaN               NaN         NaN          NaN                 1.0   \n",
      "6663      NaN               NaN         NaN          NaN                 1.0   \n",
      "6894    24/52               NaN         NaN    1000194.0                 1.0   \n",
      "7522      NaN               NaN         NaN          NaN                 1.0   \n",
      "7580      NaN               NaN         NaN          NaN                 3.0   \n",
      "7596      NaN               NaN         NaN          NaN                 4.0   \n",
      "7599      NaN               NaN         NaN          NaN                 4.0   \n",
      "\n",
      "       VAHED_MALI  ACCT_AC_JOURNAL_ID  BASEINFO_RECORDID    C_YEAR_ID  \n",
      "1466  200000138.0                 NaN                NaN          NaN  \n",
      "2269  200000138.0                 NaN                NaN          NaN  \n",
      "2270  200000138.0                 NaN                NaN          NaN  \n",
      "2271  200000138.0                 NaN                NaN          NaN  \n",
      "2990          NaN                 NaN                NaN          NaN  \n",
      "3462          NaN                 NaN                NaN          NaN  \n",
      "4361          NaN                 NaN                NaN          NaN  \n",
      "5616          NaN                 NaN                NaN          NaN  \n",
      "6663  200000138.0                 NaN        469638726.0  469637411.0  \n",
      "6894  200000141.0                 NaN        469638588.0  469637411.0  \n",
      "7522  200000138.0                 NaN        469638651.0          NaN  \n",
      "7580  469638358.0                 NaN        469638630.0          NaN  \n",
      "7596  200000529.0                 NaN        469638805.0          NaN  \n",
      "7599  200000529.0                 NaN        469638805.0          NaN  \n",
      "\n",
      "[14 rows x 43 columns]\n",
      "     INOUT_ID  AD_CLIENT_ID  AD_ORG_ID ISACTIVE          CREATED  CREATEDBY  \\\n",
      "19  210032665     104000002          0        Y  12/26/2013 9:49  210035294   \n",
      "\n",
      "            UPDATED  UPDATEDBY  NAME DESCRIPTION  ... SUB_REF_ORG  STRING3  \\\n",
      "19  12/26/2013 9:50  210035294   NaN         NaN  ...         NaN      NaN   \n",
      "\n",
      "    M_INOUT_AMVAL_ID DOCUMENTNO1 LOCATIONS_ID  ACCT_AC_HOLDING_ID  VAHED_MALI  \\\n",
      "19               NaN         NaN          NaN                 1.0         NaN   \n",
      "\n",
      "    ACCT_AC_JOURNAL_ID  BASEINFO_RECORDID  C_YEAR_ID  \n",
      "19                 NaN                NaN        NaN  \n",
      "\n",
      "[1 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "fialized = inout_df.loc[inout_df[\"C_DOCSTATUS_ID\"] == 3000025]\n",
    "print(fialized)\n",
    "drafted = inout_df.loc[inout_df[\"C_DOCSTATUS_ID\"] == 3000006]\n",
    "print(drafted)\n",
    "waiting = inout_df.loc[inout_df[\"C_DOCSTATUS_ID\"] == 3000018]\n",
    "print(waiting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3a1ec",
   "metadata": {},
   "source": [
    "As we finished this phase we saw how much our previous two phases helped us in understanding the core of our datasets and also to clean it and get the most knowledge on what are the ups and downs and quality of what we have our hands-on, only after those steps we had the courage and enough resource to analyze our datasets and know the answers to some real questions about assets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
