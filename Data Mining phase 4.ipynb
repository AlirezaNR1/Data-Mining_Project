{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c1a701",
   "metadata": {},
   "source": [
    "# Data Mining Phase 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f00601",
   "metadata": {},
   "source": [
    "Faridreza Momtazzandi 9812762601 Alireza Nourbakhsh 9812762496"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1a764",
   "metadata": {},
   "source": [
    "We finally reached our last and fourth phase which is to use all the knowledge we got from previous phases and finally answer the main questions we're facing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc88ca0d",
   "metadata": {},
   "source": [
    "At this point, we know our datasets and we're familiar with their shortcomings so if our employer asks us some critical questions about these datasets and try to get as much detail possible on how he wants to use this dataset in his favor we can now try to use all we know and answer them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3c086",
   "metadata": {},
   "source": [
    "As we saw in phase Three, our main focus is to look for incoming and outcoming assets and after getting information on three main topics which are the Incoming rate of assets, Count and Value of assets based on Holding and Draft or finalized accounting document we can move on to what we need to do in this phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd56d8c",
   "metadata": {},
   "source": [
    "Like the last phase, we need to discuss three main topics and we get into detail on each one of them in their parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c11aa7",
   "metadata": {},
   "source": [
    "# 1.The ratio of bought assets to returned assets based on the organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cec7f5",
   "metadata": {},
   "source": [
    "Unlike the last phase which we focused on incoming assets based on holding and accounting units, in this part, we're trying to work on organizations and as we look into our datasets we learn some attributes are used to demonstrate organization such as AD_ORG_ID and REF_ORG in INOUT dataset and AD_ORG_REF_ID in PRODUCTINSTANCE dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b602e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41265ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inout_df = pd.read_csv('E:\\ce\\data mining\\DataSets\\INOUT.csv' , low_memory = False)\n",
    "inoutline_df = pd.read_csv('E:\\ce\\data mining\\DataSets\\INOUTLINE.csv' , low_memory = False)\n",
    "productinstance_df = pd.read_csv('E:\\ce\\data mining\\DataSets\\PRODUCTINSTANCE.csv' , encoding='cp1252' , low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80451e25",
   "metadata": {},
   "source": [
    "We want to look into bought asstes which is all the assets in our dataset and returned assets are assets that got aborted. first lets see how AD_ORG_ID, REF_ORG and AD_ORG_REF_ID are doing so we can use them to find what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033a16b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m let's see all the organizations base on AD_ORG_ID attribute\n",
      "\u001b[90m\n",
      "0            5717\n",
      "104000002    1883\n",
      "Name: AD_ORG_ID, dtype: int64\n",
      "\u001b[94m______________________________________________________________\n",
      " let's see all the organizations base on REF_ORG attribute\n",
      "\u001b[90m\n",
      "200000137.0    331\n",
      "200000114.0    273\n",
      "200000654.0    252\n",
      "210000089.0    242\n",
      "200000138.0    203\n",
      "              ... \n",
      "210000118.0      1\n",
      "469638078.0      1\n",
      "469638503.0      1\n",
      "469638393.0      1\n",
      "469637721.0      1\n",
      "Name: REF_ORG, Length: 171, dtype: int64\n",
      "\u001b[94m______________________________________________________________\n",
      " let's see all the organizations base on AD_ORG_REF_ID attribute\n",
      "\u001b[90m\n",
      "106536008.0    42572\n",
      "200000137.0     9096\n",
      "200000138.0     5185\n",
      "469732738.0     5012\n",
      "469678455.0     3636\n",
      "               ...  \n",
      "210033816.0        1\n",
      "105005321.0        1\n",
      "469685459.0        1\n",
      "469739817.0        1\n",
      "469637579.0        1\n",
      "Name: AD_ORG_REF_ID, Length: 359, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[94m let's see all the organizations base on AD_ORG_ID attribute\")\n",
    "print('\\033[90m')\n",
    "print(inout_df['AD_ORG_ID'].value_counts())\n",
    "print(\"\\033[94m______________________________________________________________\")\n",
    "print(\" let's see all the organizations base on REF_ORG attribute\")\n",
    "print('\\033[90m')\n",
    "print(inout_df['REF_ORG'].value_counts())\n",
    "print(\"\\033[94m______________________________________________________________\")\n",
    "print(\" let's see all the organizations base on AD_ORG_REF_ID attribute\")\n",
    "print('\\033[90m')\n",
    "print(productinstance_df['AD_ORG_REF_ID'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee093d",
   "metadata": {},
   "source": [
    "With what we got from the code above we find an anomaly in our database although in our dictionary it's stated that AD_ORG_ID is the equivalent to REF_ORG their values are different so we can't see which of them can be useful for us so it's better to use AD_ORG_REF_ID attribute because not only it's in our PRODUCTINSTANCE dataset and it means we have this attribute for all incoming assets, also we can use RETURNAMVALTOANBAR attribute which as its name suggests is the state of returned assets. Let's see how this attribute works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af78cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m let's see values of RETURNAMVALTOANBAR:\n",
      "\u001b[90m\n",
      "4.0    6290\n",
      "1.0    2703\n",
      "3.0     257\n",
      "2.0      18\n",
      "Name: RETURNAMVALTOANBAR, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[94m let's see values of RETURNAMVALTOANBAR:\")\n",
    "print('\\033[90m')\n",
    "print(productinstance_df['RETURNAMVALTOANBAR'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1be709",
   "metadata": {},
   "source": [
    "As we saw in the dictionary RETURNAMVALTOANBAR attribute can have four values which are: 1 for Used usable, 2 for The asset is required to repair, 3 for Separable abortion, and 4 for Inseparable abortion so we're looking out for 3 and 4 results. In the code below we try to find the ratio of bought assets to returned assets based on organization and use AD_ORG_REF_ID and RETURNAMVALTOANBAR attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a3e3a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000137.0    5685\n",
      "dtype: int64\n",
      "106536008.0    196\n",
      "dtype: int64\n",
      "469732738.0    183\n",
      "dtype: int64\n",
      "469638568.0    48\n",
      "dtype: int64\n",
      "200000127.0    28\n",
      "dtype: int64\n",
      "200000141.0    24\n",
      "dtype: int64\n",
      "200000142.0    23\n",
      "dtype: int64\n",
      "469638360.0    20\n",
      "dtype: int64\n",
      "210032657.0    17\n",
      "dtype: int64\n",
      "200000129.0    17\n",
      "dtype: int64\n",
      "469638515.0    15\n",
      "dtype: int64\n",
      "469747289.0    13\n",
      "dtype: int64\n",
      "469637613.0    12\n",
      "dtype: int64\n",
      "469732686.0    11\n",
      "dtype: int64\n",
      "210000017.0    10\n",
      "dtype: int64\n",
      "200000654.0    8\n",
      "dtype: int64\n",
      "469638115.0    8\n",
      "dtype: int64\n",
      "210000001.0    8\n",
      "dtype: int64\n",
      "469733251.0    8\n",
      "dtype: int64\n",
      "469637680.0    8\n",
      "dtype: int64\n",
      "469678178.0    7\n",
      "dtype: int64\n",
      "469732631.0    7\n",
      "dtype: int64\n",
      "200000615.0    7\n",
      "dtype: int64\n",
      "469732813.0    7\n",
      "dtype: int64\n",
      "200000220.0    6\n",
      "dtype: int64\n",
      "200000144.0    6\n",
      "dtype: int64\n",
      "200000653.0    6\n",
      "dtype: int64\n",
      "469738837.0    6\n",
      "dtype: int64\n",
      "469732633.0    5\n",
      "dtype: int64\n",
      "210000080.0    5\n",
      "dtype: int64\n",
      "469737873.0    5\n",
      "dtype: int64\n",
      "469737677.0    5\n",
      "dtype: int64\n",
      "210034398.0    5\n",
      "dtype: int64\n",
      "469637868.0    5\n",
      "dtype: int64\n",
      "200000627.0    4\n",
      "dtype: int64\n",
      "210034287.0    4\n",
      "dtype: int64\n",
      "469739828.0    4\n",
      "dtype: int64\n",
      "469736320.0    4\n",
      "dtype: int64\n",
      "210034190.0    4\n",
      "dtype: int64\n",
      "200000167.0    4\n",
      "dtype: int64\n",
      "200000407.0    3\n",
      "dtype: int64\n",
      "469738661.0    3\n",
      "dtype: int64\n",
      "210034667.0    3\n",
      "dtype: int64\n",
      "210034257.0    3\n",
      "dtype: int64\n",
      "469732682.0    3\n",
      "dtype: int64\n",
      "210034397.0    3\n",
      "dtype: int64\n",
      "210034740.0    3\n",
      "dtype: int64\n",
      "200000138.0    3\n",
      "dtype: int64\n",
      "210000071.0    3\n",
      "dtype: int64\n",
      "200000484.0    3\n",
      "dtype: int64\n",
      "200000471.0    3\n",
      "dtype: int64\n",
      "469732739.0    3\n",
      "dtype: int64\n",
      "210034616.0    2\n",
      "dtype: int64\n",
      "200000192.0    2\n",
      "dtype: int64\n",
      "469732626.0    2\n",
      "dtype: int64\n",
      "200000548.0    2\n",
      "dtype: int64\n",
      "210619769.0    2\n",
      "dtype: int64\n",
      "469732661.0    2\n",
      "dtype: int64\n",
      "210000089.0    2\n",
      "dtype: int64\n",
      "469637895.0    2\n",
      "dtype: int64\n",
      "200000115.0    2\n",
      "dtype: int64\n",
      "200000723.0    2\n",
      "dtype: int64\n",
      "210000087.0    2\n",
      "dtype: int64\n",
      "469637963.0    2\n",
      "dtype: int64\n",
      "200000663.0    2\n",
      "dtype: int64\n",
      "200000585.0    2\n",
      "dtype: int64\n",
      "469637973.0    2\n",
      "dtype: int64\n",
      "200000632.0    1\n",
      "dtype: int64\n",
      "469735605.0    1\n",
      "dtype: int64\n",
      "200000487.0    1\n",
      "dtype: int64\n",
      "469732652.0    1\n",
      "dtype: int64\n",
      "210034337.0    1\n",
      "dtype: int64\n",
      "469732720.0    1\n",
      "dtype: int64\n",
      "200000599.0    1\n",
      "dtype: int64\n",
      "469733076.0    1\n",
      "dtype: int64\n",
      "200000119.0    1\n",
      "dtype: int64\n",
      "469732655.0    1\n",
      "dtype: int64\n",
      "200000143.0    1\n",
      "dtype: int64\n",
      "469747188.0    1\n",
      "dtype: int64\n",
      "469732727.0    1\n",
      "dtype: int64\n",
      "469732810.0    1\n",
      "dtype: int64\n",
      "469638346.0    1\n",
      "dtype: int64\n",
      "210000011.0    1\n",
      "dtype: int64\n",
      "210000098.0    1\n",
      "dtype: int64\n",
      "469732708.0    1\n",
      "dtype: int64\n",
      "200000116.0    1\n",
      "dtype: int64\n",
      "469638544.0    1\n",
      "dtype: int64\n",
      "469735538.0    1\n",
      "dtype: int64\n",
      "469732629.0    1\n",
      "dtype: int64\n",
      "469740215.0    1\n",
      "dtype: int64\n",
      "469732659.0    1\n",
      "dtype: int64\n",
      "200000114.0    1\n",
      "dtype: int64\n",
      "200000634.0    1\n",
      "dtype: int64\n",
      "200000130.0    1\n",
      "dtype: int64\n",
      "469738783.0    1\n",
      "dtype: int64\n",
      "469732657.0    1\n",
      "dtype: int64\n",
      "469678455.0    1\n",
      "dtype: int64\n",
      "469638210.0    1\n",
      "dtype: int64\n",
      "200000715.0    1\n",
      "dtype: int64\n",
      "469732627.0    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for ind in productinstance_df.index:\n",
    "    if productinstance_df['RETURNAMVALTOANBAR'][ind] == 3:\n",
    "        result.append(productinstance_df['AD_ORG_REF_ID'][ind])\n",
    "    \n",
    "    elif productinstance_df['RETURNAMVALTOANBAR'][ind] == 4:\n",
    "        result.append(productinstance_df['AD_ORG_REF_ID'][ind])\n",
    "\n",
    "for ind in pd.Series(result).value_counts().index:\n",
    "    print(pd.Series(result).value_counts().loc[[ind]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba7428",
   "metadata": {},
   "source": [
    "After we wrote the code above we checked each orgonization for it's RETURNAMVALTOANBAR attribute and added to a list if it's 3 or 4 so we can now see how much returned assets each organization has, for example organization 200000137 has the most returned assets which is 5685, 106536008 and 469732738 comes after it. also we can see the organizations with the least assets and it's only 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd03c0",
   "metadata": {},
   "source": [
    "Finally our first question is finished and we know the ratio of bought assets to returned assets based on organization so we can move on to next part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56306e7e",
   "metadata": {},
   "source": [
    "# 2.Analysis of asset inflow to asset outflow by time and organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6de3e3",
   "metadata": {},
   "source": [
    "For this part, we're gonna take a look at the inflow of assets to outflow assets and analyze them by time and organization. The only attributes we can use for this part are CREATED and UPDATED attributes which are in every dataset but we choose PRODUCTINSTANCE so we can make sure assets are all taken look at! let's see what these attributes returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f18ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m let's see all the values of CREATED attribute\n",
      "\u001b[90m\n",
      "1/14/2015 12:33     212087\n",
      "10/31/2019 7:11      79967\n",
      "4/30/2015 10:02      61370\n",
      "5/19/2017 12:02      34066\n",
      "10/26/2014 14:39     12901\n",
      "                     ...  \n",
      "5/16/2018 13:16          1\n",
      "5/16/2018 13:10          1\n",
      "5/16/2018 13:01          1\n",
      "5/16/2018 12:49          1\n",
      "60212                    1\n",
      "Name: CREATED, Length: 92756, dtype: int64\n",
      "\u001b[94m______________________________________________________________\n",
      " let's see all the values of UPDATED attribute\n",
      "\u001b[90m\n",
      "10/31/2019 7:11    77656\n",
      "2/12/2022 14:54    45377\n",
      "5/19/2017 12:02    24423\n",
      "1/14/2015 12:33    17944\n",
      "6/1/2019 12:04      8887\n",
      "                   ...  \n",
      "2/20/2021 9:19         1\n",
      "4/23/2020 13:16        1\n",
      "7/7/2021 13:03         1\n",
      "9/11/2018 11:18        1\n",
      "11/2/2019 7:27         1\n",
      "Name: UPDATED, Length: 207714, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[94m let's see all the values of CREATED attribute\")\n",
    "print('\\033[90m')\n",
    "print(productinstance_df['CREATED'].value_counts())\n",
    "print(\"\\033[94m______________________________________________________________\")\n",
    "print(\" let's see all the values of UPDATED attribute\")\n",
    "print('\\033[90m')\n",
    "print(productinstance_df['UPDATED'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29231a",
   "metadata": {},
   "source": [
    "So What we need for this part other than CREATED and UPDATED attributes is an attribute to demonstrate organizations in which we use the AD_ORG_REF_ID attribute as we used before so let's get what we need for this part and start analyzing asset inflow to asset outflow by time and organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f11220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "created = []\n",
    "updated = []\n",
    "organization = []\n",
    "ind = len(productinstance_df.index) - 1\n",
    "while ind >= 0:\n",
    "    if not productinstance_df['CREATED'][ind] in created:\n",
    "        created.append(productinstance_df['CREATED'][ind])\n",
    "        updated.append(productinstance_df['UPDATED'][ind])\n",
    "        organization.append(productinstance_df['AD_ORG_REF_ID'][ind])\n",
    "    ind -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19b850",
   "metadata": {},
   "source": [
    "What we did in our last cell was to get every individual created values and the last updated value it has assigned to it and also we got the organization that asset has. Let's check if our three lists are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de50b82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92757\n",
      "92757\n",
      "92757\n"
     ]
    }
   ],
   "source": [
    "print(len(created))\n",
    "print(len(updated))\n",
    "print(len(organization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34eafa2",
   "metadata": {},
   "source": [
    "As we see all the lists have exactly 92757 values and that's the number of our individual created values. Unfortunately printing 92757 values three times is time consuming so let's only print 5 examples of these lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38e0891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/12/2022 13:01 9/12/2022 13:01 200000137.0\n",
      "9/12/2022 11:33 9/12/2022 11:33 469638568.0\n",
      "9/12/2022 10:24 9/12/2022 10:24 200000137.0\n",
      "9/12/2022 9:17 9/12/2022 9:17 200000137.0\n",
      "9/8/2022 13:03 9/8/2022 13:03 200000137.0\n"
     ]
    }
   ],
   "source": [
    "print(created[26], updated[26], organization[26])\n",
    "print(created[34], updated[34], organization[34])\n",
    "print(created[42], updated[42], organization[42])\n",
    "print(created[49], updated[49], organization[49])\n",
    "print(created[135], updated[135], organization[135])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b29d3",
   "metadata": {},
   "source": [
    "After all the code we've written we can now have a complete understanding on our assets, their last updated value and their assigned organization. so we can now analyse and get any information we wish based in time and organization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053aad8",
   "metadata": {},
   "source": [
    "# 3.The status of similar products and the price prediction of each product according to its cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a1df0",
   "metadata": {},
   "source": [
    "There are multiple ways to find similar assets such as looking for assets with updated time and price and clustering the items which share these attributes and end up with clusters of assets with the same year and almost close price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d685995",
   "metadata": {},
   "source": [
    "Another way to face this part is to get an asset and try to predict its price for the upcoming year but with these datasets and how messy they are, we can't get a meaningful prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc13ca",
   "metadata": {},
   "source": [
    "As we saw in our last phase assets only came in the years 2013 to 2022 and for the first step of clustering we can get all the assets in 8 different clusters based on their year of 'CREATED' attribute, code below demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41acd2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m Lets see how much asset came in on each year and how we documented it in PRODUCTINSTANCE dataset:\n",
      "\u001b[90m\n",
      "in 2013: 3483\n",
      "in 2014: 50848\n",
      "in 2015: 292464\n",
      "in 2016: 24760\n",
      "in 2017: 71845\n",
      "in 2018: 45691\n",
      "in 2019: 132252\n",
      "in 2020: 22441\n",
      "in 2021: 24616\n",
      "in 2022: 25657\n"
     ]
    }
   ],
   "source": [
    "year_2013 = 0\n",
    "year_2014 = 0\n",
    "year_2015 = 0 \n",
    "year_2016 = 0 \n",
    "year_2017 = 0 \n",
    "year_2018 = 0 \n",
    "year_2019 = 0 \n",
    "year_2020 = 0 \n",
    "year_2021 = 0 \n",
    "year_2022 = 0 \n",
    "\n",
    "for ind in productinstance_df.index:\n",
    "    if '2013' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2013 += 1\n",
    "    elif '2014' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2014 += 1\n",
    "    elif '2015' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2015 += 1\n",
    "    elif '2016' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2016 += 1\n",
    "    elif '2017' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2017 += 1\n",
    "    elif '2018' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2018 += 1\n",
    "    elif '2019' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2019 += 1\n",
    "    elif '2020' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2020 += 1\n",
    "    elif '2021' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2021 += 1\n",
    "    elif '2022' in str(productinstance_df['CREATED'][ind]):\n",
    "        year_2022 += 1\n",
    "print('\\033[94m Lets see how much asset came in on each year and how we documented it in PRODUCTINSTANCE dataset:')\n",
    "print('\\033[90m')\n",
    "print('in 2013:' , year_2013)\n",
    "print('in 2014:' , year_2014)\n",
    "print('in 2015:' , year_2015)\n",
    "print('in 2016:' , year_2016)\n",
    "print('in 2017:' , year_2017)\n",
    "print('in 2018:' , year_2018)\n",
    "print('in 2019:' , year_2019)\n",
    "print('in 2020:' , year_2020)\n",
    "print('in 2021:' , year_2021)\n",
    "print('in 2022:' , year_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc835867",
   "metadata": {},
   "source": [
    "Now let's do the same thing but this time add the asset's primal value to a list so we can cluster them later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a622645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2013 = []\n",
    "p_2014 = []\n",
    "p_2015 = []\n",
    "p_2016 = []\n",
    "p_2017 = []\n",
    "p_2018 = []\n",
    "p_2019 = []\n",
    "p_2020 = []\n",
    "p_2021 = []\n",
    "p_2022 = []\n",
    "\n",
    "\n",
    "for ind in productinstance_df.index:\n",
    "    if '2013' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2013.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2014' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2014.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2015' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2015.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2016' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2016.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2017' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2017.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2018' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2018.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2019' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2019.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2020' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2020.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2021' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2021.append(productinstance_df['PRIMALVALUE'][ind])\n",
    "    elif '2022' in str(productinstance_df['CREATED'][ind]):\n",
    "        p_2022.append(productinstance_df['PRIMALVALUE'][ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07145047",
   "metadata": {},
   "source": [
    "With the code above we clustered all the PRIMALVALUES based on their year in CREATED attribute! What we suggest doing at this point is to find clusters with almost equal members and a similar range of price we think the best number to choose for the number of members is 25k for each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc4671",
   "metadata": {},
   "source": [
    "With each cluster only have about 25k members we can put each year's assets as comes below:\n",
    "* 2013: 1 cluster\n",
    "* 2014: 2 cluster\n",
    "* 2015: 12 cluster\n",
    "* 2016: 1 cluster\n",
    "* 2017: 3 cluster\n",
    "* 2018: 2 cluster\n",
    "* 2019: 6 cluster\n",
    "* 2020: 1 cluster\n",
    "* 2021: 1 cluster\n",
    "* 2022: 1 cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d770fa9b",
   "metadata": {},
   "source": [
    "so we end up with exactly 30 clusters! and we'll sort each cluster based on its value but unfortunately, the PRODUCTINSTANCE dataset doesn't have enough records so we can't get any useful information but if our dataset was better by what we just did we could predict any product's price, we just need to know what year we want to check this product in and look for it in the cluster it belongs too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ccc9c8",
   "metadata": {},
   "source": [
    "As we finished the last phase of this project we learned that after getting to know our dataset, doing necessary preprocessing on it, and answering some real-world questions about it we can finally learn enough about our dataset to analyze, predict or any other data-related need our employer might have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
